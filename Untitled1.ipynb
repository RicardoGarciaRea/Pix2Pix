{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"13xmnpZwtlVSONCfcioOIxijRLM918NQb","authorship_tag":"ABX9TyOelEVQhA80WUNe0/2UA9ZG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"gAj42WLeFUFB"},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","#RUTA RAIZ\n","PATH=\"/content/drive/My Drive\"\n","#ruta de datos de entrada\n","INPATH= PATH +'/motos3'\n","#ruta de datos de salida \n","OUTPATH=PATH +'/motos'\n","#RUTA DE LOS CHECHKPOINTS\n","CKPATH=PATH +'/moto3'\n","imgurls=!ls -1 \"{INPATH}\"\n","\n","\n","n=50\n","train_n=round(n*0.80)\n","#Listado randomizado \n","randurls=np.copy(imgurls)\n","np.random.seed(23)#solo para el tutorial \n","np.random.shuffle(randurls)\n","#Particiom train/tet\n","tr_urls=randurls[:train_n]\n","ts_urls= randurls[train_n:n]\n","print(len(imgurls),len(tr_urls),len(ts_urls))\n","#rescalar imagenes\n","IMG_WIDTH=256\n","IMG_HEIGHT=256\n","\n","def resize(inimg,tgimg,height,width):\n","    \n","  inimg=tf.image.resize(inimg,[height,width])\n","  tgimg=tf.image.resize(tgimg,[height,width])\n","  return inimg,tgimg\n","#normaliza el rango[-1, +1]\n","\n","def normalize(inimg,tgimg):\n","  inimg=(inimg/127.5)-1\n","  tgimg=(tgimg/127.5)-1\n","  return inimg,tgimg\n","@tf.function()\n","#aumentacion de datos :random crop+flip\n","def random_jitter(inimg,tgimg):\n","  \n","  inimg,tgimg = resize(inimg,tgimg,286,286)\n","  \n","  stacked_image=tf.stack([inimg,tgimg], axis=0)\n","  cropped_image = tf.image.random_crop(stacked_image, size=[2,IMG_HEIGHT,IMG_WIDTH,3])\n","  \n","  inimg,tgimg=cropped_image[0],cropped_image[1]\n","  \n","  if tf.random.uniform(()) > 0.5 :\n","  \n","    inimg=tf.image.flip_left_right(inimg)\n","    tgimg=tf.image.flip_left_right(tgimg)\n","  return inimg,tgimg\n","\n","def load_image(filename,augment=True):\n","  inimg=tf.cast(tf.image.decode_jpeg(tf.io.read_file(INPATH+'/'+filename)),tf.float32)[..., :3]\n","  \n","  tgimg=tf.cast(tf.image.decode_jpeg(tf.io.read_file(OUTPATH+'/'+filename)),tf.float32)[..., :3]\n","  \n","  inimg,tgimg=resize(inimg,tgimg,IMG_HEIGHT,IMG_WIDTH)\n","  if augment:\n","    inimg,tgimg = random_jitter(inimg,tgimg)\n","  inimg,tgimg= normalize(inimg,tgimg)\n","  return inimg, tgimg      \n","def load_train_image(filename):\n","  return load_image(filename,True)\n","def load_test_image(filename):\n","  return load_image(filename,False)\n","\n","plt.imshow(((load_train_image(randurls[0])[1]) + 1) / 2) \n","train_dataset=tf.data.Dataset.from_tensor_slices(tr_urls)\n","train_dataset=train_dataset.map(load_train_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","train_dataset=train_dataset.batch(1)\n","for inimg,tgimg in  train_dataset.take(5):\n","  print(tgimg.shape)\n","plt.imshow(((tgimg[0,...]) + 1) / 2)\n","plt.show()\n","test_dataset=tf.data.Dataset.from_tensor_slices(ts_urls)\n","test_dataset=test_dataset.map(load_test_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","test_dataset=test_dataset.batch(1)\n","from tensorflow.keras.layers import *\n","from tensorflow.keras import *\n","def downsample(filters,apply_batchnorm=True):\n","  initializer=tf.random_normal_initializer(0,0.02)\n","  result=Sequential()\n","  #capa convolucional\n","  result.add(Conv2D(filters, \n","                    kernel_size=4,\n","                    strides=2,\n","                    padding=\"same\",\n","                    kernel_initializer=initializer,\n","                    use_bias=not apply_batchnorm))\n","  if apply_batchnorm:\n","  #capa de batch normalization\n","      result.add(BatchNormalization())\n","  #capa de activacion\n","  result.add(ReLU())\n","  return result\n","downsample(64)  \n","def upsample(filters,apply_dropout=False):\n","  initializer=tf.random_normal_initializer(0,0.02)\n","  result=Sequential()\n","  #capa convolucional\n","  result.add(Conv2DTranspose(filters, \n","                              kernel_size=4,\n","                              strides=2,\n","                              padding=\"same\",\n","                              kernel_initializer=initializer,\n","                              use_bias=False))\n","  result.add(BatchNormalization())\n","  if apply_dropout:\n","  #capa de batch normalization\n","      result.add( Dropout(0.5))\n","  #capa de activacion\n","  result.add(ReLU())\n","  return result\n","upsample(64)  \n","def Generator():\n","  inputs=tf.keras.layers.Input(shape=[None,None,3])\n","\n","  down_stack=[\n","              downsample(64, apply_batchnorm=False),\n","              downsample(128),\n","              downsample(256),\n","              downsample(512),\n","              downsample(512),\n","              downsample(512),\n","              downsample(512),\n","              downsample(512),\n","  ]\n","  up_stack=[\n","            upsample(512,apply_dropout=True),\n","            upsample(512,apply_dropout=True),\n","            upsample(512,apply_dropout=True),\n","            upsample(512),\n","            upsample(256),\n","            upsample(128),\n","            upsample(64),\n","\n","  ]\n","  initializer=tf.random_normal_initializer(0,0.02)\n","  last=Conv2DTranspose(filters=3,\n","                       kernel_size=4,\n","                       strides=2,\n","                       padding=\"same\",\n","                       kernel_initializer=initializer,\n","                       activation=\"tanh\")\n","  x=inputs\n","  s= []  \n","  concat=Concatenate()\n","  \n","  for down in down_stack:\n","    x= down(x)\n","    s.append(x)\n","  \n","  s =reversed(s[:-1])  \n","  \n","  for up ,sk in zip (up_stack,s):\n","    x=up(x)\n","    x=concat([x,sk])\n","\n","  last=last(x)\n","  return Model(inputs=inputs,outputs=last )\n","generator=Generator()\n","gen_output=generator(((inimg+1)*255), training=False)\n","plt.imshow(gen_output[0,...])\n","def Discriminator():\n","  ini=Input(shape=[None,None,3],name=\"input_img\")\n","  gen=Input(shape=[None,None,3],name=\"gener_img\")\n","  con=concatenate([ini,gen])\n","  initializer=tf.random_normal_initializer(0,0.2)\n","  down1=downsample(64,apply_batchnorm=False)(con)\n","  down2=downsample(128)(down1)\n","  down3=downsample(256)(down2)\n","  down4=downsample(512)(down3)\n","\n","  last=tf.keras.layers.Conv2D(filters=1,\n","                              kernel_size=4,\n","                              strides=1,\n","                              kernel_initializer=initializer,\n","                              padding=\"same\")(down4)\n","  return tf.keras.Model(inputs=[ini,gen],outputs=last)                                      \n","discriminator=Discriminator()       \n","disc_out=discriminator([((inimg+1)*255),gen_output], training=False)\n","plt.imshow(disc_out[0,...,-1],vmin=20,vmax=20,cmap='RdBu_r')\n","plt.colorbar()\n","disc_out.shape       \n","loss_object=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","def discriminator_loss(disc_real_output, disc_generated_output):\n","  #Diferencia entre los true por ser real y el detectado por el discriminador\n","  real_loss=loss_object(tf.ones_like(disc_real_output),disc_real_output)\n","  #Diferencia entre los false por ser generado y el detectado por el discriminador\n","  generated_loss=loss_object(tf.zeros_like(disc_generated_output),disc_generated_output)\n","\n","  total_disc_loss=real_loss + generated_loss\n","\n","  return total_disc_loss\n","LAMBDA=100\n","def generator_loss(disc_generated_output,gen_output,target):\n","  gan_loss=loss_object(tf.ones_like(disc_generated_output),disc_generated_output)\n","\n","  #mean absolute error\n","  l1_loss=tf.reduce_mean(tf.abs(target - gen_output))\n","  total_gen_loss= gan_loss + (LAMBDA* l1_loss)\n","  return total_gen_loss\n","\n","def generate_images(model,test_input, tar, save_filename=False,display_imgs=True):\n","  prediction=model(test_input,training=True)\n","  if save_filename:\n","    tf.keras.preprocessing.image.save_img(PATH + '/Output/'+save_filename +'.jpg', prediction[0,...])\n","  plt.figure(figsize=(10,10))\n","\n","  display_list=[test_input[0],tar[0],prediction[0]]\n","  title=['Input image','Ground Truth','Predicted Image']\n","  if display_imgs:\n","    for i in range(3):\n","      plt.subplot(1,3,i+1)\n","      plt.title(title[i])\n","      plt.imshow(display_list[i]*0.5+0.5)\n","      plt.axis('off')\n","  plt.show()\n","@tf.function() \n","def train_step(input_image,target):\n","  with tf.GradientTape() as gen_tape, tf.GradientTape() as discr_tape:\n","    output_image =generator(input_image,training=True)\n","    output_gen_discr=discriminator([output_image,input_image],training=True)\n","    output_trg_discr=discriminator([output_image,input_image],training=True)\n","    discr_loss=discriminator_loss(output_trg_discr,output_gen_discr)\n","    gen_loss=generator_loss(output_gen_discr,output_image,target)\n","\n","    generator_grads=gen_tape.gradient(gen_loss,generator.trainable_variables)\n","    discriminator_grads=discr_tape.gradient(discr_loss,discriminator.trainable_variables)\n","    generator_optimizer.apply_gradients(zip(generator_grads,generator.trainable_variables))\n","    discriminator_optimizer.apply_gradients(zip(discriminator_grads,discriminator.trainable_variables))\n","\n","\n","\n","\n","\n","from  IPython.display import clear_output\n","\n","def train(dataset, epochs):\n","  for epoch in range (epochs):\n","    imgi=0\n","    for input_image, target in dataset:\n","      print('epoch'+str(epoch)+'-train:' +str(imgi)+'/'+str(len(tr_urls)))\n","      imgi+=1\n","      train_step(input_image,target)\n","      clear_output(wait=True)\n","    imgi=0\n","    for inp,tar in test_dataset.take(5):\n","      generate_images(generator,inp,tar,str(imgi)+'_'+str(epoch),display_imgs=True)\n","      imgi+=1\n","    #saving the model every 20 epochs\n","    if (epoch+1)%50==0:\n","      checkpoint.save(file_prefix=checkpoint_prefix)\n","train(train_dataset,600)\n","import os\n","generator_optimizer    =tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","discriminator_optimizer=tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","\n","checkpoint_prefix=os.path.join(CKPATH,\"ckpt\")\n","checkpoint=tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n","                               discriminator_optimizer=discriminator_optimizer,\n","                               generator=generator,\n","                               discriminator=discriminator)\n","checkpoint.restore(tf.train.latest_checkpoint(CKPATH))"],"execution_count":null,"outputs":[]}]}